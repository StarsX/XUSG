//--------------------------------------------------------------------------------------
// Copyright (c) XU, Tianchen. All rights reserved.
//--------------------------------------------------------------------------------------

#include "XUSGMachineLearning.h"

using namespace XUSG;

#define APPEND_FLAG(type, dmlType, flags, flag, none) ((flags & type::flag) == type::flag ? dmlType##_##flag : dmlType##_##none)
#define APPEND_EXECUTION_FLAG(flags, flag) APPEND_FLAG(ExecutionFlag, DML_EXECUTION_FLAG, flags, flag, NONE)

DML_TENSOR_DATA_TYPE ML::GetDMLTensorDataType(TensorDataType dataType)
{
	static DML_TENSOR_DATA_TYPE dataTypes[] =
	{
		DML_TENSOR_DATA_TYPE_UNKNOWN,
		DML_TENSOR_DATA_TYPE_FLOAT32,
		DML_TENSOR_DATA_TYPE_FLOAT16,
		DML_TENSOR_DATA_TYPE_UINT32,
		DML_TENSOR_DATA_TYPE_UINT16,
		DML_TENSOR_DATA_TYPE_UINT8,
		DML_TENSOR_DATA_TYPE_INT32,
		DML_TENSOR_DATA_TYPE_INT16,
		DML_TENSOR_DATA_TYPE_INT8
	};

	return dataTypes[static_cast<uint32_t>(dataType)];
}

DML_OPERATOR_TYPE ML::GetDMLOpteratorType(OperatorType operatorType)
{
	static DML_OPERATOR_TYPE operatorTypes[] =
	{
		DML_OPERATOR_INVALID,
		DML_OPERATOR_ELEMENT_WISE_IDENTITY,
		DML_OPERATOR_ELEMENT_WISE_ABS,
		DML_OPERATOR_ELEMENT_WISE_ACOS,
		DML_OPERATOR_ELEMENT_WISE_ADD,
		DML_OPERATOR_ELEMENT_WISE_ASIN,
		DML_OPERATOR_ELEMENT_WISE_ATAN,
		DML_OPERATOR_ELEMENT_WISE_CEIL,
		DML_OPERATOR_ELEMENT_WISE_CLIP,
		DML_OPERATOR_ELEMENT_WISE_COS,
		DML_OPERATOR_ELEMENT_WISE_DIVIDE,
		DML_OPERATOR_ELEMENT_WISE_EXP,
		DML_OPERATOR_ELEMENT_WISE_FLOOR,
		DML_OPERATOR_ELEMENT_WISE_LOG,
		DML_OPERATOR_ELEMENT_WISE_LOGICAL_AND,
		DML_OPERATOR_ELEMENT_WISE_LOGICAL_EQUALS,
		DML_OPERATOR_ELEMENT_WISE_LOGICAL_GREATER_THAN,
		DML_OPERATOR_ELEMENT_WISE_LOGICAL_LESS_THAN,
		DML_OPERATOR_ELEMENT_WISE_LOGICAL_NOT,
		DML_OPERATOR_ELEMENT_WISE_LOGICAL_OR,
		DML_OPERATOR_ELEMENT_WISE_LOGICAL_XOR,
		DML_OPERATOR_ELEMENT_WISE_MAX,
		DML_OPERATOR_ELEMENT_WISE_MEAN,
		DML_OPERATOR_ELEMENT_WISE_MIN,
		DML_OPERATOR_ELEMENT_WISE_MULTIPLY,
		DML_OPERATOR_ELEMENT_WISE_POW,
		DML_OPERATOR_ELEMENT_WISE_CONSTANT_POW,
		DML_OPERATOR_ELEMENT_WISE_RECIP,
		DML_OPERATOR_ELEMENT_WISE_SIN,
		DML_OPERATOR_ELEMENT_WISE_SQRT,
		DML_OPERATOR_ELEMENT_WISE_SUBTRACT,
		DML_OPERATOR_ELEMENT_WISE_TAN,
		DML_OPERATOR_ELEMENT_WISE_THRESHOLD,
		DML_OPERATOR_ELEMENT_WISE_QUANTIZE_LINEAR,
		DML_OPERATOR_ELEMENT_WISE_DEQUANTIZE_LINEAR,
		DML_OPERATOR_ACTIVATION_ELU,
		DML_OPERATOR_ACTIVATION_HARDMAX,
		DML_OPERATOR_ACTIVATION_HARD_SIGMOID,
		DML_OPERATOR_ACTIVATION_IDENTITY,
		DML_OPERATOR_ACTIVATION_LEAKY_RELU,
		DML_OPERATOR_ACTIVATION_LINEAR,
		DML_OPERATOR_ACTIVATION_LOG_SOFTMAX,
		DML_OPERATOR_ACTIVATION_PARAMETERIZED_RELU,
		DML_OPERATOR_ACTIVATION_PARAMETRIC_SOFTPLUS,
		DML_OPERATOR_ACTIVATION_RELU,
		DML_OPERATOR_ACTIVATION_SCALED_ELU,
		DML_OPERATOR_ACTIVATION_SCALED_TANH,
		DML_OPERATOR_ACTIVATION_SIGMOID,
		DML_OPERATOR_ACTIVATION_SOFTMAX,
		DML_OPERATOR_ACTIVATION_SOFTPLUS,
		DML_OPERATOR_ACTIVATION_SOFTSIGN,
		DML_OPERATOR_ACTIVATION_TANH,
		DML_OPERATOR_ACTIVATION_THRESHOLDED_RELU,
		DML_OPERATOR_CONVOLUTION,
		DML_OPERATOR_GEMM,
		DML_OPERATOR_REDUCE,
		DML_OPERATOR_AVERAGE_POOLING,
		DML_OPERATOR_LP_POOLING,
		DML_OPERATOR_MAX_POOLING,
		DML_OPERATOR_ROI_POOLING,
		DML_OPERATOR_SLICE,
		DML_OPERATOR_CAST,
		DML_OPERATOR_SPLIT,
		DML_OPERATOR_JOIN,
		DML_OPERATOR_PADDING,
		DML_OPERATOR_VALUE_SCALE_2D,
		DML_OPERATOR_UPSAMPLE_2D,
		DML_OPERATOR_GATHER,
		DML_OPERATOR_SPACE_TO_DEPTH,
		DML_OPERATOR_DEPTH_TO_SPACE,
		DML_OPERATOR_TILE,
		DML_OPERATOR_TOP_K,
		DML_OPERATOR_BATCH_NORMALIZATION,
		DML_OPERATOR_MEAN_VARIANCE_NORMALIZATION,
		DML_OPERATOR_LOCAL_RESPONSE_NORMALIZATION,
		DML_OPERATOR_LP_NORMALIZATION,
		DML_OPERATOR_RNN,
		DML_OPERATOR_LSTM,
		DML_OPERATOR_GRU
	};

	return operatorTypes[static_cast<uint32_t>(operatorType)];
}

DML_TENSOR_FLAGS ML::GetDMLTensorFlag(TensorFlag tensorFlag)
{
	static DML_TENSOR_FLAGS tensorFlags[] =
	{
		DML_TENSOR_FLAG_OWNED_BY_DML
	};

	if (tensorFlag == TensorFlag::NONE) return DML_TENSOR_FLAG_NONE;

	const auto index = Log2(static_cast<uint32_t>(tensorFlag));

	return tensorFlags[index];
}

DML_TENSOR_FLAGS ML::GetDMLTensorFlags(TensorFlag tensorFlags)
{
	auto flags = DML_TENSOR_FLAG_NONE;
	flags |= (tensorFlags & TensorFlag::MANAGED) == TensorFlag::MANAGED ? DML_TENSOR_FLAG_OWNED_BY_DML : DML_TENSOR_FLAG_NONE;

	return flags;
}

DML_EXECUTION_FLAGS ML::GetDMLExecutionFlag(ExecutionFlag executionFlag)
{
	static DML_EXECUTION_FLAGS executionFlags[] =
	{
		DML_EXECUTION_FLAG_ALLOW_HALF_PRECISION_COMPUTATION,
		DML_EXECUTION_FLAG_DISABLE_META_COMMANDS,
		DML_EXECUTION_FLAG_DESCRIPTORS_VOLATILE
	};

	if (executionFlag == ExecutionFlag::NONE) return DML_EXECUTION_FLAG_NONE;

	const auto index = Log2(static_cast<uint32_t>(executionFlag));

	return executionFlags[index];
}

DML_EXECUTION_FLAGS ML::GetDMLExecutionFlags(ExecutionFlag executionFlags)
{
	auto flags = DML_EXECUTION_FLAG_NONE;
	flags |= APPEND_EXECUTION_FLAG(executionFlags, ALLOW_HALF_PRECISION_COMPUTATION);
	flags |= APPEND_EXECUTION_FLAG(executionFlags, DISABLE_META_COMMANDS);
	flags |= APPEND_EXECUTION_FLAG(executionFlags, DESCRIPTORS_VOLATILE);

	return flags;
}

DML_CONVOLUTION_MODE ML::GetDMLConvolutionMode(ConvolutionMode convolutionMode)
{
	static DML_CONVOLUTION_MODE convolutionModes[] =
	{
		DML_CONVOLUTION_MODE_CONVOLUTION,
		DML_CONVOLUTION_MODE_CROSS_CORRELATION
	};

	return convolutionModes[static_cast<uint32_t>(convolutionMode)];
}

DML_CONVOLUTION_DIRECTION ML::GetDMLConvolutionDirection(ConvolutionDirection convolutionDirection)
{
	static DML_CONVOLUTION_DIRECTION convolutionDirections[] =
	{
		DML_CONVOLUTION_DIRECTION_FORWARD,
		DML_CONVOLUTION_DIRECTION_BACKWARD
	};

	return convolutionDirections[static_cast<uint32_t>(convolutionDirection)];
}

DML_INTERPOLATION_MODE ML::GetDMLInterpolationMode(InterpolationType interpolationMode)
{
	static DML_INTERPOLATION_MODE interpolationModes[] =
	{
		DML_INTERPOLATION_MODE_NEAREST_NEIGHBOR,
		DML_INTERPOLATION_MODE_LINEAR
	};

	return interpolationModes[static_cast<uint32_t>(interpolationMode)];
}
